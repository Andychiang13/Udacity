![](https://video.udacity-data.com/topher/2018/March/5ab588e3_image-captioning/image-captioning.png "Logo Title Text 2")

Image Captioning Model 

## Project Overview 

In this project, you will create a neural network architecture to automatically generate captions from images. 

After using the Microsoft Common Objects in COntext [(MS COCO) dataset](http://cocodataset.org/#home) to train your network, you will test your network on novel images! 

## Project Instructions 

The project is structured as a series of Jupyter notebooks that are designed to be completed in sequential order: 

* 0\_Dataset.ipynb
* 1\_Preliminaries.ipynb
* 2\_Training.ipynb
* 3\_Inference.ipynb 

You can find these notebooks in the Udacity workspace that appears in the concept titled **Project: Image Captioning**. This workspace provides a Jupyter notebook server directly in your browser. 

You can read more about workspaces (and how to toggle GPU support) in the following concept (**Introduction to GPU Workspaces**). This concept will show you how to toggle GPU support in the workspace. 
> 
> **You MUST enable GPU mode for this project and submit your project after you complete the code in the workspace.** 

> A completely trained model is expected to take between 5-12 hours to train well on a GPU; it is suggested that you look at early patterns in loss (what happens in the first hour or so of training) as you make changes to your model, so that you only have to spend this large amount of time training your _final_ model.
